{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pymorphy2\n",
    "\n",
    "def pymorphy2_311_hotfix():\n",
    "    from inspect import getfullargspec\n",
    "    from pymorphy2.units.base import BaseAnalyzerUnit\n",
    "\n",
    "    def _get_param_names_311(klass):\n",
    "        if klass.__init__ is object.__init__:\n",
    "            return []\n",
    "        args = getfullargspec(klass.__init__).args\n",
    "        return sorted(args[1:])\n",
    "\n",
    "    setattr(BaseAnalyzerUnit, '_get_param_names', _get_param_names_311)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите любую новость с любого новостного портала\n",
    "\n",
    "• Проведите парсинг текста новости\n",
    "\n",
    "• Очистите текст от стоп-слов\n",
    "\n",
    "• Оцените тональность новости с помощью библиотеки dostoevsky\n",
    "\n",
    "• В случае проблем с установкой dostoevsky проведите лемматизацию текста и выведите 5 самых частых слов в новости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ixbt.com/news/2024/11/26/kalifornija-protiv-trampa-i-maska-shtat-sobiraetsja-davat-skidki-na-vse-jelektromobili-krome-tesla.html\"\n",
    "page = requests.get(url)\n",
    "print(page.status_code)\n",
    "soup = \"\"\n",
    "if page.status_code == 200:\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nГубернатор Калифорнии против Трампа и Маска. Штат собирается давать скидки на все электромобили, кроме Tesla\\n\\nСуществующую скидку 7500 долларов при Трампе должны отменить \\n\\n\\nГубернатор Калифорнии Гэвин Ньюсом объявил, что, если Трамп решит отменить федеральную политику налоговых льгот для электромобилей после вступления в должность, Калифорния предоставит отдельную налоговую льготу покупателям электромобилей.\\nНо он также упомянул, что нынешнее предложение не будет распространяться на Tesla. Конкретные детали необходимо постепенно согласовывать с государственным собранием, поэтому могут быть корректировки. «Речь идет о создании рыночных условий, которые позволят большему количеству автопроизводителей укорениться», — заявили в администрации губернатора.\\nДо этого Соединенные Штаты предоставляли налоговые льготы в размере до 7500 долларов покупателям соответствующих электромобилей, но Трамп, как ожидается, планирует отменить эту политику.\\n\\n\\nИзображение Midjourney\\n\\n\\nНьюсом заявил, что Калифорния может возобновить программу скидок на чистые автомобили. Сообщается, что программа была свернута в 2023 году после финансирования 594 000 автомобилей и экономии 1,7 млрд литров топлива.\\nОн подчеркнул: «Потребители продолжают доказывать неправоту скептиков – транспортные средства на новых источниках энергии будут продолжать существовать. Мы облегчим людям покупку экологически чистых транспортных средств».\\nОн призвал Законодательное собрание штата созвать специальную сессию для принятия законов штата, «защищенных от Трампа», предоставив больше финансирования канцелярии генерального прокурора для реагирования на федеральные проблемы.\\nВ офисе Ньюсома сообщили, что продажи автомобилей с нулевым уровнем выбросов в Калифорнии превысили 2 миллиона штук. В последние годы штат принял несколько мер по поэтапному отказу от автомобилей, грузовиков, поездов и газонокосилок, работающих на ископаемом топливе. '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_header = soup.find(class_ = 'b-article__header').get_text()\n",
    "news_body = soup.find(class_ = 'b-article__content').get_text()\n",
    "text = news_header + '\\n' + news_body\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = text.lower().translate(str.maketrans('', '', string.punctuation)).translate(str.maketrans('', '', string.digits)).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Игорь\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 175\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_ru = stopwords.words(\"russian\")\n",
    "words_list2 = [word for word in words_list if word not in stopwords_ru]\n",
    "print(len(words_list), len(words_list2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С установкой dostoevsky возникли проблемы. Терпение, выделенное на борьбу с ними иссякло."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>калифорния</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>штат</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>электромобиль</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>трамп</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>автомобиль</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  count\n",
       "0     калифорния      5\n",
       "1           штат      5\n",
       "2  электромобиль      4\n",
       "3          трамп      4\n",
       "4     автомобиль      4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymorphy2_311_hotfix()\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "lemmatized_words = [morph.parse(word)[0].normal_form for word in words_list2]\n",
    "data = pd.DataFrame(lemmatized_words, columns=[\"words\"])\n",
    "words_count = data['words'].value_counts().reset_index()\n",
    "words_count.columns = ['word', 'count']\n",
    "words_count.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
